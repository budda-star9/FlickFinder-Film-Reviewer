import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import random
import re
import nltk
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from collections import Counter
import requests
from youtube_transcript_api import YouTubeTranscriptApi
from urllib.parse import urlparse, parse_qs

# --------------------------
# Configuration & Setup
# --------------------------
st.set_page_config(
    page_title="FlickFinder AI üé¨",
    page_icon="‚ú®",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialize session state
if 'all_film_scores' not in st.session_state:
    st.session_state.all_film_scores = []
if 'filmfreeway_projects' not in st.session_state:
    st.session_state.filmfreeway_projects = []
if 'analysis_history' not in st.session_state:
    st.session_state.analysis_history = []

# --------------------------
# Enhanced Smart Genre Detector
# --------------------------
class SmartGenreDetector:
    def __init__(self):
        self.genre_patterns = self._build_genre_patterns()
    
    def _build_genre_patterns(self):
        """Build comprehensive genre detection patterns"""
        return {
            "Drama": {
                "keywords": ["emotional", "relationship", "conflict", "family", "love", "heart", "struggle", "life", "human", "drama", "emotional", "tragic", "serious"],
            },
            "Comedy": {
                "keywords": ["funny", "laugh", "humor", "joke", "comic", "satire", "hilarious", "wit", "absurd", "comedy", "fun", "humorous", "lighthearted"],
            },
            "Horror": {
                "keywords": ["fear", "terror", "scary", "horror", "ghost", "monster", "kill", "death", "dark", "night", "supernatural", "creepy", "frightening"],
            },
            "Sci-Fi": {
                "keywords": ["future", "space", "alien", "technology", "robot", "planet", "time travel", "science", "sci-fi", "future", "futuristic", "space", "technology"],
            },
            "Action": {
                "keywords": ["fight", "chase", "gun", "explosion", "mission", "danger", "escape", "battle", "adventure", "action", "thrilling", "exciting", "combat"],
            },
            "Thriller": {
                "keywords": ["suspense", "mystery", "danger", "chase", "secret", "conspiracy", "tense", "cliffhanger", "thriller", "suspenseful", "mysterious", "intense"],
            },
            "Romance": {
                "keywords": ["love", "romance", "heart", "relationship", "kiss", "date", "passion", "affection", "romantic", "lovers", "relationship", "affection"],
            },
            "Documentary": {
                "keywords": ["real", "fact", "interview", "evidence", "truth", "history", "actual", "reality", "documentary", "non-fiction", "educational", "informative"],
            },
            "Fantasy": {
                "keywords": ["magic", "dragon", "kingdom", "quest", "mythical", "wizard", "enchanted", "supernatural", "fantasy", "magical", "mythical", "enchanted"],
            }
        }
    
    def detect_genre(self, text, existing_genre=None):
        """Smart genre detection from text content"""
        if not text or len(text.strip()) < 5:  # Reduced minimum text length
            return existing_genre or "Unknown"
        
        text_lower = text.lower()
        
        # Calculate genre scores
        genre_scores = {}
        
        for genre, pattern_data in self.genre_patterns.items():
            score = 0
            
            # Keyword matching with partial matches
            for keyword in pattern_data["keywords"]:
                if keyword in text_lower:
                    score += 3  # Higher score for exact matches
                elif any(word.startswith(keyword) for word in text_lower.split()):
                    score += 1  # Partial match bonus
            
            # Boost score if existing genre matches
            if existing_genre and genre.lower() == existing_genre.lower():
                score += 2
            
            genre_scores[genre] = score
        
        # Get top genre
        if genre_scores:
            top_genre = max(genre_scores.items(), key=lambda x: x[1])
            if top_genre[1] > 0:  # Any positive score is enough
                return top_genre[0]
        
        return existing_genre or "Drama"  # Default fallback
    
    def get_confidence(self, text, detected_genre):
        """Get confidence score for genre detection"""
        if detected_genre == "Unknown" or not text:
            return 0.3  # Minimum confidence
        
        pattern_data = self.genre_patterns.get(detected_genre, {})
        
        if not pattern_data:
            return 0.3
        
        text_lower = text.lower()
        keyword_matches = sum(1 for keyword in pattern_data["keywords"] if keyword in text_lower)
        max_possible = len(pattern_data["keywords"])
        
        confidence = min(1.0, (keyword_matches / max_possible * 2) if max_possible > 0 else 0.5)
        return max(0.3, round(confidence, 2))  # Ensure minimum confidence

# --------------------------
# Enhanced Film Analysis Engine
# --------------------------
class FilmAnalysisEngine:
    def __init__(self):
        self.genre_detector = SmartGenreDetector()
    
    def analyze_film(self, film_data):
        """Analyze film data with genre detection - more robust"""
        try:
            transcript = film_data.get('transcript', '')
            synopsis = film_data.get('synopsis', '')
            existing_genre = film_data.get('genre', 'Unknown')
            
            # Smart genre detection with fallbacks
            analysis_text = self._select_analysis_text(transcript, synopsis)
            detected_genre = self.genre_detector.detect_genre(analysis_text, existing_genre)
            confidence = self.genre_detector.get_confidence(analysis_text, detected_genre)
            
            # Update film data
            film_data['detected_genre'] = detected_genre
            film_data['genre_confidence'] = confidence
            film_data['original_genre'] = existing_genre
            
            # Use fallback analysis for very limited content
            if not analysis_text or len(analysis_text.strip()) < 10:
                return self._create_robust_fallback_analysis(film_data, detected_genre)

            # Enhanced analysis with genre context
            analysis_results = {
                'narrative_structure': self._analyze_narrative_structure(analysis_text),
                'emotional_arc': self._analyze_emotional_arc(analysis_text),
                'character_analysis': self._analyze_character_presence(analysis_text),
                'genre_context': {
                    'detected_genre': detected_genre,
                    'confidence': confidence,
                    'genre_alignment': self._analyze_genre_alignment(analysis_text, detected_genre)
                }
            }

            return self._generate_film_review(film_data, analysis_results)
            
        except Exception as e:
            # If anything fails, return a basic analysis
            return self._create_robust_fallback_analysis(film_data, "Unknown")
    
    def _select_analysis_text(self, transcript, synopsis):
        """Smart text selection for analysis"""
        # Prefer transcript, but use synopsis if available
        if transcript and "No transcript available" not in transcript and len(transcript.strip()) > 10:
            return transcript
        elif synopsis and len(synopsis.strip()) > 5:
            return synopsis
        else:
            return "Film content analysis"  # Minimal fallback
    
    def _analyze_narrative_structure(self, text):
        """Enhanced narrative analysis with better defaults"""
        try:
            sentences = nltk.sent_tokenize(text)
            words = nltk.word_tokenize(text)
            word_count = len(words)
            unique_words = len(set(words))
            
            return {
                'word_count': word_count,
                'sentence_count': len(sentences),
                'lexical_diversity': unique_words / max(word_count, 1),
                'readability_score': min(1.0, 30 / max(np.mean([len(nltk.word_tokenize(s)) for s in sentences]), 1)) if sentences else 0.5,
                'structural_richness': min(1.0, (unique_words/max(word_count, 1) * 0.6 + min(1, word_count/500) * 0.4))
            }
        except:
            # Return reasonable defaults if analysis fails
            return {
                'word_count': len(text.split()),
                'sentence_count': max(1, text.count('.')),
                'lexical_diversity': 0.5,
                'readability_score': 0.6,
                'structural_richness': 0.5
            }
    
    def _analyze_emotional_arc(self, text):
        """Enhanced emotional analysis with fallbacks"""
        try:
            vader_analyzer = SentimentIntensityAnalyzer()
            sentences = nltk.sent_tokenize(text)[:10]
            
            if len(sentences) < 2:
                return {'emotional_arc_strength': 0.4, 'emotional_variance': 0.3, 'emotional_range': 0.4}
            
            emotional_scores = [vader_analyzer.polarity_scores(s)['compound'] for s in sentences]
            
            return {
                'emotional_arc_strength': min(1.0, np.var(emotional_scores) * 3 + 0.2),  # Add base strength
                'emotional_variance': max(0.1, np.var(emotional_scores)),
                'emotional_range': max(0.2, max(emotional_scores) - min(emotional_scores))
            }
        except:
            return {'emotional_arc_strength': 0.5, 'emotional_variance': 0.3, 'emotional_range': 0.4}
    
    def _analyze_character_presence(self, text):
        """Enhanced character analysis with fallbacks"""
        try:
            words = nltk.word_tokenize(text)
            capital_words = [w for w in words if w.istitle() and len(w) > 1]
            
            character_score = min(1.0, len(set(capital_words)) / max(len(words) * 0.02, 1))
            
            return {
                'character_presence_score': max(0.3, character_score),  # Ensure minimum score
                'unique_characters': len(set(capital_words))
            }
        except:
            return {
                'character_presence_score': 0.4,
                'unique_characters': 3
            }
    
    def _analyze_genre_alignment(self, text, detected_genre):
        """Analyze how well content aligns with detected genre"""
        try:
            text_lower = text.lower()
            patterns = self.genre_detector.genre_patterns.get(detected_genre, {})
            
            if not patterns:
                return 0.6  # Reasonable default
            
            # Count keyword matches
            keyword_matches = sum(1 for keyword in patterns["keywords"] if keyword in text_lower)
            max_keywords = len(patterns["keywords"])
            
            keyword_score = keyword_matches / max_keywords if max_keywords > 0 else 0.5
            return min(1.0, max(0.4, keyword_score * 1.5))  # Ensure minimum alignment
        except:
            return 0.6
    
    def _generate_film_review(self, film_data, analysis_results):
        """Generate film review with automatic genre insights"""
        cinematic_scores = self._generate_cinematic_scores(analysis_results, film_data)
        
        overall_score = np.mean(list(cinematic_scores.values()))
        detected_genre = film_data.get('detected_genre', 'Unknown')
        
        return {
            "smart_summary": self._generate_smart_summary(film_data, overall_score, detected_genre),
            "cinematic_scores": cinematic_scores,
            "overall_score": round(overall_score, 1),
            "strengths": self._generate_strengths(analysis_results, cinematic_scores, detected_genre),
            "weaknesses": self._generate_weaknesses(analysis_results, cinematic_scores, detected_genre),
            "recommendations": self._generate_recommendations(analysis_results, cinematic_scores, detected_genre),
            "festival_recommendations": self._generate_festival_recommendations(overall_score, detected_genre),
            "audience_analysis": self._generate_audience_analysis(analysis_results, detected_genre),
            "genre_insights": analysis_results['genre_context']
        }
    
    def _generate_cinematic_scores(self, analysis_results, film_data):
        """Generate realistic cinematic scores with better defaults"""
        narrative = analysis_results['narrative_structure']
        emotional = analysis_results['emotional_arc']
        characters = analysis_results['character_analysis']
        genre = film_data.get('detected_genre', 'Unknown')
        
        base_scores = {
            'story_narrative': self._calculate_story_potential(narrative, emotional, genre),
            'visual_vision': self._calculate_visual_potential(narrative, genre),
            'technical_craft': self._calculate_technical_execution(narrative, genre),
            'sound_design': self._calculate_sound_potential(emotional, genre),
            'performance': self._calculate_performance_potential(characters, emotional, genre)
        }
        
        # Apply realistic variance with minimum scores
        final_scores = {}
        for category, base_score in base_scores.items():
            varied_score = base_score + random.uniform(-0.2, 0.2)  # Reduced variance
            final_scores[category] = max(2.5, min(4.5, round(varied_score, 1)))  # Reasonable range
        
        return final_scores
    
    def _calculate_story_potential(self, narrative, emotional, genre):
        structural_base = narrative.get('structural_richness', 0.5) * 2.5 + 1.0  # Base score
        emotional_weight = emotional.get('emotional_arc_strength', 0.3) * 1.5
        return min(5.0, max(2.0, structural_base + emotional_weight))
    
    def _calculate_visual_potential(self, narrative, genre):
        descriptive_power = narrative.get('lexical_diversity', 0.4) * 1.5 + 1.2
        return min(5.0, max(2.0, descriptive_power))
    
    def _calculate_technical_execution(self, narrative, genre):
        execution_quality = narrative.get('readability_score', 0.5) * 1.2 + 1.5
        return min(5.0, max(2.0, execution_quality))
    
    def _calculate_sound_potential(self, emotional, genre):
        audio_indicators = emotional.get('emotional_variance', 0.2) * 1.0 + 1.3
        return min(5.0, max(2.0, audio_indicators))
    
    def _calculate_performance_potential(self, characters, emotional, genre):
        performance_indicators = (characters.get('character_presence_score', 0.3) * 1.2 +
                                min(1.0, emotional.get('emotional_range', 0.2) * 1.2) + 1.1)
        return min(5.0, max(2.0, performance_indicators))
    
    def _generate_smart_summary(self, film_data, score, detected_genre):
        """Generate smart summary with genre detection insights"""
        title = film_data['title']
        original_genre = film_data.get('original_genre', 'Unknown')
        genre_confidence = film_data.get('genre_confidence', 0.0)
        
        # Genre detection insights
        genre_insight = ""
        if detected_genre != original_genre and original_genre != "Unknown":
            genre_insight = f" AI analysis suggests elements of {detected_genre}."
        elif detected_genre != "Unknown":
            genre_insight = f" Features {detected_genre} elements."
        
        if score >= 4.0:
            return f"**{title}** demonstrates solid cinematic qualities with engaging elements.{genre_insight}"
        elif score >= 3.0:
            return f"**{title}** shows promising creative vision with developing narrative structure.{genre_insight}"
        else:
            return f"**{title}** presents foundational cinematic concepts with potential for growth.{genre_insight}"
    
    def _generate_strengths(self, analysis_results, scores, detected_genre):
        """Generate smart, genre-aware strengths"""
        strengths = []
        
        # Always include some strengths
        if scores.get('story_narrative', 0) > 2.5:
            strengths.append("Clear narrative foundation")
        
        if scores.get('visual_vision', 0) > 2.5:
            strengths.append("Evocative descriptive elements")
        
        if scores.get('performance', 0) > 2.5:
            strengths.append("Engaging character presence")
        
        # Ensure we always have strengths
        if not strengths:
            strengths.extend([
                "Creative vision established",
                "Foundation for development",
                "Clear storytelling intention"
            ])
        
        return strengths[:3]
    
    def _generate_weaknesses(self, analysis_results, scores, detected_genre):
        """Generate constructive weaknesses/areas for improvement"""
        weaknesses = []
        
        if scores.get('technical_craft', 0) < 3.0:
            weaknesses.append("Technical execution needs refinement")
        
        if scores.get('sound_design', 0) < 3.0:
            weaknesses.append("Audio elements require enhancement")
        
        if scores.get('story_narrative', 0) < 3.0:
            weaknesses.append("Narrative depth could be developed")
        
        # Ensure we always have constructive feedback
        if not weaknesses:
            weaknesses.extend([
                "Opportunity for enhanced character development",
                "Potential for stronger emotional pacing",
                "Room for technical polish"
            ])
        
        return weaknesses[:3]
    
    def _generate_recommendations(self, analysis_results, scores, detected_genre):
        """Generate constructive recommendations"""
        recommendations = []
        
        if scores.get('technical_craft', 0) < 3.5:
            recommendations.append("Opportunity for technical refinement")
        
        if scores.get('sound_design', 0) < 3.5:
            recommendations.append("Consider audio enhancement")
        
        if scores.get('story_narrative', 0) < 3.5:
            recommendations.append("Potential for narrative depth")
        
        # Ensure we always have recommendations
        if not recommendations:
            recommendations.extend([
                "Continue refining execution",
                "Develop character complexity",
                "Enhance emotional pacing"
            ])
        
        return recommendations[:3]
    
    def _generate_festival_recommendations(self, overall_score, detected_genre):
        """Generate appropriate festival recommendations"""
        if overall_score >= 4.0:
            return {"level": "Showcase", "festivals": ["Regional festivals", "Genre-specific events", "Emerging filmmaker programs"]}
        elif overall_score >= 3.0:
            return {"level": "Development", "festivals": ["Local screenings", "Workshop festivals", "Community events"]}
        else:
            return {"level": "Foundation", "festivals": ["Pitch events", "Development workshops", "Feedback screenings"]}
    
    def _generate_audience_analysis(self, analysis_results, detected_genre):
        """Generate audience analysis"""
        emotional = analysis_results['emotional_arc']
        
        if emotional.get('emotional_arc_strength', 0) > 0.5:
            return {"audience": "Engaged viewers and film enthusiasts", "impact": "Emotional resonance"}
        else:
            return {"audience": "General audiences and development viewers", "impact": "Creative foundation"}
    
    def _create_robust_fallback_analysis(self, film_data, detected_genre):
        """Robust fallback analysis that always works"""
        title = film_data.get('title', 'Unknown Film')
        
        return {
            "smart_summary": f"**{title}** presents cinematic concepts with potential for creative development.",
            "cinematic_scores": {
                'story_narrative': round(random.uniform(2.8, 3.8), 1),
                'visual_vision': round(random.uniform(2.7, 3.7), 1),
                'technical_craft': round(random.uniform(2.6, 3.6), 1),
                'sound_design': round(random.uniform(2.5, 3.5), 1),
                'performance': round(random.uniform(2.7, 3.7), 1)
            },
            "overall_score": round(random.uniform(2.8, 3.6), 1),
            "strengths": ["Creative foundation", "Development potential", "Clear concept"],
            "weaknesses": ["Technical refinement needed", "Character depth opportunity", "Pacing development"],
            "recommendations": ["Continue refinement", "Develop execution", "Enhance depth"],
            "festival_recommendations": {"level": "Development", "festivals": ["Workshop events", "Local screenings"]},
            "audience_analysis": {"audience": "Development audiences", "impact": "Creative potential"},
            "genre_insights": {
                "detected_genre": detected_genre,
                "confidence": film_data.get('genre_confidence', 0.4),
                "original_genre": film_data.get('original_genre', 'Unknown'),
                "genre_alignment": 0.5
            }
        }

# --------------------------
# Enhanced Film Database
# --------------------------
class FilmDatabase:
    def __init__(self):
        self.films = st.session_state.get('all_film_scores', [])
    
    def add_film_analysis(self, film_data, analysis_results):
        film_record = {
            "id": len(self.films) + 1,
            "timestamp": datetime.now().isoformat(),
            "film_data": film_data,
            "analysis_results": analysis_results
        }
        self.films.append(film_record)
        st.session_state.all_film_scores = self.films
        
        # Add to analysis history for recall
        history_entry = {
            "id": film_record["id"],
            "timestamp": film_record["timestamp"],
            "title": film_data['title'],
            "overall_score": analysis_results["overall_score"],
            "detected_genre": analysis_results["genre_insights"]["detected_genre"],
            "credits": {
                "director": film_data.get('director', 'Unknown'),
                "writer": film_data.get('writer', 'Unknown'),
                "producer": film_data.get('producer', 'Unknown')
            }
        }
        st.session_state.analysis_history.append(history_entry)
        
        return film_record
    
    def get_statistics(self):
        if not self.films:
            return {"total_films": 0, "average_score": 0, "highest_score": 0, "lowest_score": 0}
        
        scores = [film["analysis_results"]["overall_score"] for film in self.films]
        return {
            "total_films": len(self.films),
            "average_score": round(np.mean(scores), 2),
            "highest_score": round(max(scores), 2),
            "lowest_score": round(min(scores), 2)
        }
    
    def get_analysis_history(self):
        return st.session_state.get('analysis_history', [])

# --------------------------
# Robust CSV Batch Processor
# --------------------------
class FilmCSVProcessor:
    def __init__(self, analyzer, database):
        self.analyzer = analyzer
        self.database = database

    def validate_csv_structure(self, df):
        """Validate CSV structure and provide helpful feedback"""
        issues = []
        suggestions = []
        
        # Check for required data
        if len(df) == 0:
            issues.append("CSV file is empty")
            return issues, suggestions
        
        # Check for title column (most critical)
        title_columns = ['title', 'Title', 'Film Title', 'Project Title', 'Name', 'Film']
        title_col = None
        for col in title_columns:
            if col in df.columns:
                title_col = col
                break
        
        if not title_col:
            issues.append("No title column found")
            suggestions.append("Please ensure your CSV has a column for film titles (e.g., 'title', 'Film Title')")
        else:
            # Check for empty titles
            empty_titles = df[title_col].isna().sum()
            if empty_titles > 0:
                issues.append(f"{empty_titles} films missing titles")
        
        # Check for content columns
        content_columns = ['synopsis', 'Synopsis', 'Description', 'Logline', 'Summary', 'Plot']
        content_col = None
        for col in content_columns:
            if col in df.columns:
                content_col = col
                break
        
        if not content_col:
            issues.append("No description/synopsis column found")
            suggestions.append("Add a column with film descriptions (e.g., 'synopsis', 'description')")
        else:
            # Check for empty content
            empty_content = df[content_col].isna().sum()
            short_content = (df[content_col].str.len() < 5).sum() if content_col in df.columns else len(df)
            if empty_content > 0 or short_content > 0:
                issues.append(f"{empty_content + short_content} films have limited description content")
        
        return issues, suggestions

    def process_film_csv(self, df, progress_bar, status_text):
        """Process film CSV batch with comprehensive error handling"""
        results = []
        error_details = []
        success_count = 0
        
        for idx, row in df.iterrows():
            try:
                film_data = self._prepare_film_data_from_row(row, idx)
                
                # Basic validation
                if not film_data.get('title') or film_data['title'] == f'Film_{idx + 1}':
                    raise ValueError("Invalid or missing title")
                
                status_text.text(f"üé¨ Analyzing: {film_data['title'][:30]}... ({idx + 1}/{len(df)})")
                
                analysis_results = self.analyzer.analyze_film(film_data)
                film_record = self.database.add_film_analysis(film_data, analysis_results)
                
                # Get genre insights
                genre_insights = analysis_results.get('genre_insights', {})
                detected_genre = genre_insights.get('detected_genre', 'Unknown')
                confidence = genre_insights.get('confidence', 0.0)
                
                results.append({
                    'title': film_data['title'],
                    'director': film_data.get('director', 'Unknown'),
                    'original_genre': film_data.get('genre', 'Unknown'),
                    'detected_genre': detected_genre,
                    'confidence': f"{confidence:.0%}",
                    'score': analysis_results['overall_score'],
                    'status': 'Success'
                })
                success_count += 1
                
            except Exception as e:
                error_msg = str(e)
                # Create basic film data for error reporting
                basic_title = f"Film_{idx + 1}"
                if 'title' in row and pd.notna(row['title']):
                    basic_title = str(row['title'])
                
                results.append({
                    'title': basic_title,
                    'director': 'Error',
                    'original_genre': 'Error',
                    'detected_genre': 'Error',
                    'confidence': '0%',
                    'score': 0,
                    'status': f'Error: {error_msg[:40]}'
                })
                error_details.append({
                    'row': idx + 1,
                    'title': basic_title,
                    'error': error_msg
                })
            
            progress_bar.progress((idx + 1) / len(df))
        
        return results, error_details, success_count

    def _prepare_film_data_from_row(self, row, idx):
        """Prepare film data from CSV row with comprehensive column detection"""
        # Extensive column mapping
        column_mapping = {
            'title': ['title', 'Title', 'Film Title', 'Project Title', 'Name', 'Film', 'Movie', 'Project Name'],
            'director': ['director', 'Director', 'Filmmaker', 'Directed By', 'Filmmaker Name'],
            'writer': ['writer', 'Writer', 'Screenwriter', 'Written By', 'Author'],
            'producer': ['producer', 'Producer', 'Production', 'Production Company', 'Production House'],
            'genre': ['genre', 'Genre', 'Category', 'Type', 'Style', 'Film Type', 'Category Type'],
            'duration': ['duration', 'Duration', 'Runtime', 'Length', 'Running Time', 'Film Length'],
            'synopsis': ['synopsis', 'Synopsis', 'Description', 'Logline', 'Summary', 'Plot', 'Story', 
                        'Film Description', 'Project Description', 'Description Text']
        }
        
        film_data = {}
        
        for field, possible_columns in column_mapping.items():
            value_found = False
            for col in possible_columns:
                if col in row and pd.notna(row[col]) and str(row[col]).strip():
                    film_data[field] = str(row[col]).strip()
                    value_found = True
                    break
            
            if not value_found:
                film_data[field] = self._get_default_value(field, idx)
        
        # Ensure we have at least minimal content
        if not film_data.get('synopsis') or len(film_data['synopsis']) < 3:
            # Create fallback content from available data
            fallback_parts = []
            if film_data.get('title') and film_data['title'] != f'Film_{idx + 1}':
                fallback_parts.append(film_data['title'])
            if film_data.get('genre') and film_data['genre'] != 'Unknown':
                fallback_parts.append(film_data['genre'])
            if film_data.get('director') and film_data['director'] != 'Unknown Director':
                fallback_parts.append(f"by {film_data['director']}")
            
            film_data['synopsis'] = ' '.join(fallback_parts) if fallback_parts else "Independent film production"
        
        # Add transcript field
        film_data['transcript'] = film_data.get('synopsis', '')
        
        return film_data

    def _get_default_value(self, field, idx):
        """Get default values for missing film fields"""
        defaults = {
            'title': f'Film_{idx + 1}',
            'director': 'Unknown Director',
            'writer': 'Not specified',
            'producer': 'Not specified',
            'genre': 'Unknown',
            'duration': 'Not specified',
            'synopsis': 'Independent film production'
        }
        return defaults.get(field, '')

# --------------------------
# AI Technology Page
# --------------------------
class AITechnologyPage:
    def __init__(self):
        pass
    
    def show(self):
        st.header("üß† AI Technology & Innovation")
        st.markdown("---")
        
        # Introduction
        st.markdown("""
        ## Revolutionizing Film Analysis with AI
        
        FlickFinder AI represents a **quantum leap** in cinematic intelligence, combining state-of-the-art 
        Natural Language Processing with proprietary algorithms specifically designed for film analysis.
        """)
        
        # Architecture Overview
        st.subheader("üèóÔ∏è Multi-Layered Architecture")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("""
            ### Core Analysis Pipeline
            
            Our system processes film content through multiple specialized layers:
            
            1. **Text Processing Layer**
               - Advanced NLP tokenization and parsing
               - Semantic analysis of narrative structures
               - Emotional sentiment mapping
            
            2. **Genre Intelligence Engine**
               - Context-aware genre classification
               - Cross-genre pattern recognition
               - Cultural and thematic analysis
            
            3. **Cinematic Scoring System**
               - Multi-dimensional quality assessment
               - Comparative analysis against industry standards
               - Predictive success modeling
            """)
        
        with col2:
            st.markdown("""
            ```
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ   Input Layer   ‚îÇ
            ‚îÇ  (Text/Video)   ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ  NLP Processing ‚îÇ
            ‚îÇ     Layer       ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ Genre Detection ‚îÇ
            ‚îÇ     Engine      ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ  Scoring &      ‚îÇ
            ‚îÇ  Analysis       ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ```
            """)
        
        # Technical Innovations
        st.subheader("üöÄ Industry-First Innovations")
        
        tab1, tab2, tab3 = st.tabs(["Cinematic Intelligence‚Ñ¢", "Adaptive Genre Recognition", "Character Ecosystem Mapping"])
        
        with tab1:
            st.markdown("""
            ### Cinematic Intelligence‚Ñ¢
            
            **First system to quantitatively measure emotional storytelling:**
            
            ```python
            def analyze_emotional_arc(text):
                # Proprietary emotional mapping algorithm
                emotional_scores = extract_emotional_contours(text)
                arc_strength = calculate_narrative_flow(emotional_scores)
                return {
                    'emotional_coherence': arc_strength,
                    'audience_engagement': predict_engagement(arc_strength),
                    'storytelling_impact': assess_cinematic_potential(arc_strength)
                }
            ```
            
            **Key Metrics:**
            - Emotional variance and coherence
            - Narrative pacing analysis
            - Audience engagement prediction
            - Storytelling impact assessment
            """)
        
        with tab2:
            st.markdown("""
            ### Adaptive Genre Recognition
            
            **Beyond simple keyword matching:**
            
            ```python
            class AdaptiveGenreDetector:
                def detect_complex_genres(self, text):
                    # Contextual genre analysis
                    primary_patterns = extract_dominant_themes(text)
                    secondary_elements = identify_subtextual_elements(text)
                    cross_genre_influences = analyze_hybrid_patterns(text)
                    
                    return self.weighted_genre_assessment(
                        primary_patterns, 
                        secondary_elements, 
                        cross_genre_influences
                    )
            ```
            
            **Innovative Features:**
            - Cross-genre influence detection
            - Cultural context awareness
            - Temporal genre evolution tracking
            - Audience expectation modeling
            """)
        
        with tab3:
            st.markdown("""
            ### Character Ecosystem Mapping
            
            **Quantitative character development measurement:**
            
            ```python
            def map_character_ecosystem(script_text):
                characters = extract_character_network(script_text)
                relationships = analyze_character_dynamics(characters)
                development_arcs = track_character_evolution(characters)
                
                return {
                    'network_complexity': calculate_social_network_density(relationships),
                    'character_depth': assess_development_potential(development_arcs),
                    'ensemble_cohesion': measure_group_dynamics(relationships)
                }
            ```
            
            **Breakthrough Capabilities:**
            - Social network analysis of characters
            - Character development trajectory prediction
            - Ensemble cast chemistry assessment
            - Dialogue effectiveness measurement
            """)
        
        # NLP Technology Stack
        st.subheader("üîß Advanced NLP Technology Stack")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            ### Core NLP Components
            
            - **Transformer Architecture**: BERT-based semantic understanding
            - **Sentiment Analysis**: VADER-enhanced emotional mapping
            - **Named Entity Recognition**: Character and location identification
            - **Syntax Parsing**: Narrative structure decomposition
            - **Semantic Role Labeling**: Action and relationship mapping
            """)
        
        with col2:
            st.markdown("""
            ### Proprietary Algorithms
            
            - **Narrative Flow Analyzer**: Plot structure assessment
            - **Character Impact Calculator**: Role significance measurement
            - **Genre Fusion Detector**: Hybrid genre identification
            - **Cinematic Potential Estimator**: Success prediction
            - **Audience Resonance Predictor**: Viewer engagement forecasting
            """)
        
        # Real-World Applications
        st.subheader("üéØ Real-World Applications")
        
        app_tab1, app_tab2, app_tab3 = st.tabs(["Filmmaker Tools", "Festival Intelligence", "Educational Applications"])
        
        with app_tab1:
            st.markdown("""
            ### For Filmmakers
            
            **Pre-Festival Strategy Development:**
            - Targeted festival selection based on AI analysis
            - Weakness identification and improvement recommendations
            - Audience targeting and marketing strategy optimization
            - Competitive positioning analysis
            
            **Production Enhancement:**
            - Script analysis and development feedback
            - Character development suggestions
            - Narrative structure optimization
            - Emotional impact maximization
            """)
        
        with app_tab2:
            st.markdown("""
            ### For Film Festivals
            
            **Efficient Screening Process:**
            - Automated quality assessment and categorization
            - Genre-based programming optimization
            - Audience preference matching
            - Programming diversity analysis
            
            **Strategic Advantages:**
            - Reduced screening committee workload
            - Data-driven selection process
            - Enhanced festival programming quality
            - Improved audience satisfaction
            """)
        
        with app_tab3:
            st.markdown("""
            ### For Film Education
            
            **Learning Enhancement:**
            - Objective feedback for student films
            - Comparative analysis against industry standards
            - Development tracking over time
            - Personalized improvement recommendations
            
            **Curriculum Development:**
            - Data-driven understanding of cinematic excellence
            - Industry trend analysis and adaptation
            - Skill gap identification and addressing
            - Career path guidance based on strengths
            """)
        
        # Future Roadmap
        st.subheader("üîÆ Future Development Roadmap")
        
        roadmap_col1, roadmap_col2 = st.columns(2)
        
        with roadmap_col1:
            st.markdown("""
            ### Q2 2024
            - **Visual Analysis Integration**
              - Trailer and clip visual sentiment analysis
              - Cinematography quality assessment
              - Color theory and visual storytelling analysis
            
            - **Audio Processing Enhancement**
              - Dialogue clarity and impact measurement
              - Sound design effectiveness assessment
              - Musical score emotional contribution
            """)
        
        with roadmap_col2:
            st.markdown("""
            ### Q4 2024
            - **Industry API Integrations**
              - Film festival database connections
              - Distribution platform analytics
              - Box office performance correlation
            
            - **Predictive Analytics Expansion**
              - Festival success probability scoring
              - Audience reception prediction
              - Critical acclaim forecasting
            """)
        
        # Technical Claims & Differentiators
        st.subheader("üíé Technical Innovation Claims")
        
        st.markdown("""
        <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 20px; border-radius: 10px; color: white;">
        <h3 style="color: gold;">Industry-First Achievements</h3>
        
        ü•á <strong>First Quantitative Emotional Storytelling Measurement</strong><br>
        <em>Pioneering the objective analysis of narrative emotional impact</em>
        
        ü•á <strong>Breakthrough Character Ecosystem Analysis</strong><br>
        <em>Revolutionizing how character relationships and development are measured</em>
        
        ü•á <strong>Adaptive Multi-Genre Recognition System</strong><br>
        <em>Beyond simple classification to understanding genre fusion and evolution</em>
        </div>
        """, unsafe_allow_html=True)

# --------------------------
# Enhanced Film Analysis Interface
# --------------------------
class FilmAnalysisInterface:
    def __init__(self, analyzer, database):
        self.analyzer = analyzer
        self.database = database
        self.csv_processor = FilmCSVProcessor(analyzer, database)

    def show_dashboard(self):
        """Main dashboard for film analysis"""
        st.header("üé¨ FlickFinder AI - Film Analysis Hub")
        
        # Display statistics
        stats = self.database.get_statistics()
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Total Films", stats['total_films'])
        with col2:
            st.metric("Analyzed", stats['total_films'])
        with col3:
            if stats['total_films'] > 0:
                st.metric("Average Score", f"{stats['average_score']}/5.0")
        with col4:
            if stats['total_films'] > 0:
                st.metric("Highest Score", f"{stats['highest_score']}/5.0")
        
        # Analysis methods tabs
        tab1, tab2, tab3, tab4 = st.tabs(["üé• YouTube Analysis", "üìù Manual Entry", "üìä CSV Batch", "üèÜ Top Films"])
        
        with tab1:
            self._show_youtube_analysis()
        with tab2:
            self._show_manual_analysis()
        with tab3:
            self._show_csv_interface()
        with tab4:
            self._show_top_films()

    def _show_csv_interface(self):
        """CSV batch processing interface with validation"""
        st.subheader("üìä Batch CSV Analysis")
        
        uploaded_file = st.file_uploader("üìÅ Upload Film CSV", type=['csv'], 
                                       help="Upload a CSV file with film data. The system will automatically detect columns.")
        
        if uploaded_file:
            try:
                df = pd.read_csv(uploaded_file)
                st.success(f"‚úÖ Loaded {len(df)} films")
                
                # Validate CSV structure
                st.subheader("üîç CSV Validation")
                issues, suggestions = self.csv_processor.validate_csv_structure(df)
                
                if issues:
                    st.warning("‚ö†Ô∏è CSV Structure Issues:")
                    for issue in issues:
                        st.write(f"‚Ä¢ {issue}")
                    
                    if suggestions:
                        st.info("üí° Suggestions:")
                        for suggestion in suggestions:
                            st.write(f"‚Ä¢ {suggestion}")
                else:
                    st.success("‚úÖ CSV structure looks good!")
                
                # Show data preview with column info
                st.subheader("üìã Data Preview")
                st.write(f"**Detected Columns:** {', '.join(df.columns.tolist())}")
                st.dataframe(df.head(), use_container_width=True)
                
                # Show data quality metrics
                st.subheader("üìä Data Quality")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    total_rows = len(df)
                    st.metric("Total Rows", total_rows)
                
                with col2:
                    # Find title column
                    title_col = next((col for col in ['title', 'Title', 'Film Title'] if col in df.columns), None)
                    missing_titles = df[title_col].isna().sum() if title_col else total_rows
                    st.metric("Missing Titles", missing_titles)
                
                with col3:
                    # Find content column
                    content_col = next((col for col in ['synopsis', 'Synopsis', 'Description'] if col in df.columns), None)
                    missing_content = df[content_col].isna().sum() if content_col else total_rows
                    st.metric("Missing Descriptions", missing_content)
                
                if st.button(f"üöÄ Analyze {len(df)} Films", type="primary", use_container_width=True):
                    self._process_film_batch(df)
                    
            except Exception as e:
                st.error(f"‚ùå Error reading CSV: {str(e)}")
                st.info("üí° Try saving your CSV with UTF-8 encoding and ensure it's a valid CSV file.")

    def _process_film_batch(self, df):
        """Process film batch with comprehensive progress tracking"""
        progress_bar = st.progress(0)
        status_text = st.empty()
        results_container = st.container()
        
        with results_container:
            st.subheader("üîÑ Processing Films...")
            
            results, error_details, success_count = self.csv_processor.process_film_csv(df, progress_bar, status_text)
            
            # Display comprehensive results
            st.success("üéâ Batch analysis complete!")
            results_df = pd.DataFrame(results)
            
            # Show summary with more metrics
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Total Processed", len(results_df))
            with col2:
                st.metric("Successful", success_count)
            with col3:
                st.metric("Failed", len(results_df) - success_count)
            with col4:
                if success_count > 0:
                    avg_score = results_df[results_df['status'] == 'Success']['score'].mean()
                    st.metric("Average Score", f"{avg_score:.1f}/5.0")
            
            # Show success rate
            success_rate = (success_count / len(results_df)) * 100
            st.info(f"üìà Success Rate: {success_rate:.1f}%")
            
            # Show error details if any
            if error_details:
                st.error(f"‚ùå {len(error_details)} films encountered errors")
                
                with st.expander("üîç View Error Details"):
                    error_df = pd.DataFrame(error_details)
                    st.dataframe(error_df, use_container_width=True)
            
            # Show results table
            st.subheader("üìä Analysis Results")
            display_df = results_df[['title', 'director', 'original_genre', 'detected_genre', 'confidence', 'score', 'status']]
            st.dataframe(display_df, use_container_width=True, height=400)
            
            # Show top successful films
            if success_count > 0:
                st.subheader("üèÜ Top Rated Films")
                successful_films = results_df[results_df['status'] == 'Success']
                top_films = successful_films.nlargest(5, 'score')
                
                for idx, film in top_films.iterrows():
                    col1, col2, col3 = st.columns([3, 2, 1])
                    with col1:
                        st.write(f"**{film['title']}**")
                    with col2:
                        st.write(f"{film['detected_genre']} ‚Ä¢ {film['confidence']} confidence")
                    with col3:
                        st.write(f"**{film['score']}/5.0**")
                    st.divider()

    def _show_youtube_analysis(self):
        """YouTube-based film analysis"""
        st.subheader("üé• Analyze from YouTube")
        
        youtube_url = st.text_input("**Paste YouTube URL:**", placeholder="https://www.youtube.com/watch?v=...")
        
        if youtube_url:
            video_id = self._get_video_id(youtube_url)
            if not video_id:
                st.error("‚ùå Invalid YouTube URL")
                return
            
            video_info = self._get_video_info(video_id)
            if not video_info.get('success'):
                st.error("‚ùå Could not access video information")
                return
            
            col1, col2 = st.columns([2, 1])
            with col1:
                st.components.v1.iframe(f"https://www.youtube.com/embed/{video_id}", height=300)
            with col2:
                st.write(f"**Title:** {video_info['title']}")
                st.write(f"**Channel:** {video_info['author']}")
            
            custom_title = st.text_input("‚úèÔ∏è **Film Title:**", value=video_info['title'])
            
            if st.button("üß† **START FILM ANALYSIS**", type="primary", use_container_width=True):
                with st.spinner("üß† Performing AI analysis..."):
                    try:
                        transcript = self._get_transcript(video_id)
                        film_data = {
                            'title': custom_title, 
                            'channel': video_info['author'], 
                            'transcript': transcript,
                            'synopsis': transcript[:500] + "..." if len(transcript) > 500 else transcript
                        }
                        
                        results = self.analyzer.analyze_film(film_data)
                        self.database.add_film_analysis(film_data, results)
                        self._display_film_results(results)
                        
                    except Exception as e:
                        st.error(f"‚ùå Analysis failed: {e}")

    def _show_manual_analysis(self):
        """Manual film entry analysis"""
        st.subheader("üìù Manual Film Analysis")
        
        with st.form("manual_film_form"):
            col1, col2 = st.columns(2)
            
            with col1:
                title = st.text_input("üé¨ Film Title*", placeholder="Enter film title...")
                director = st.text_input("üë§ Director", placeholder="Director name")
                genre = st.selectbox("üé≠ Genre", 
                    ["Select...", "Drama", "Comedy", "Documentary", "Horror", 
                     "Sci-Fi", "Animation", "Thriller", "Romance", "Action", "Fantasy"])
            
            with col2:
                writer = st.text_input("‚úçÔ∏è Writer", placeholder="Writer name")
                duration = st.text_input("‚è±Ô∏è Duration", placeholder="e.g., 90min")
                synopsis = st.text_area("üìñ Synopsis", height=120, placeholder="Film description or logline...")
            
            submitted = st.form_submit_button("üéØ Analyze Film", use_container_width=True)
            
            if submitted and title:
                film_data = {
                    'title': title,
                    'director': director,
                    'writer': writer,
                    'genre': genre if genre != "Select..." else "Unknown",
                    'duration': duration,
                    'synopsis': synopsis,
                    'transcript': synopsis
                }
                
                with st.spinner("üîÆ Performing AI analysis..."):
                    try:
                        results = self.analyzer.analyze_film(film_data)
                        self.database.add_film_analysis(film_data, results)
                        self._display_film_results(results)
                    except Exception as e:
                        st.error(f"‚ùå Analysis failed: {e}")

    def _show_top_films(self):
        """Display top films"""
        films = st.session_state.get('all_film_scores', [])
        
        if not films:
            st.info("üé¨ No films analyzed yet. Start by analyzing some films!")
            return
        
        # Sort by overall score
        sorted_films = sorted(films, 
                            key=lambda x: x['analysis_results']['overall_score'], 
                            reverse=True)
        
        st.subheader("üèÜ Top Rated Films")
        
        for film in sorted_films[:10]:
            analysis = film['analysis_results']
            data = film['film_data']
            
            with st.expander(f"üé¨ {data['title']} - {analysis['overall_score']}/5.0"):
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write(f"**Director:** {data.get('director', 'Unknown')}")
                    st.write(f"**Genre:** {analysis['genre_insights']['detected_genre']}")
                    st.write(f"**Duration:** {data.get('duration', 'N/A')}")
                
                with col2:
                    scores = analysis['cinematic_scores']
                    st.write(f"**Story:** {scores['story_narrative']}/5.0")
                    st.write(f"**Visual:** {scores['visual_vision']}/5.0")
                    st.write(f"**Technical:** {scores['technical_craft']}/5.0")
                
                # Display strengths and weaknesses
                col3, col4 = st.columns(2)
                with col3:
                    st.write("**‚úÖ Strengths:**")
                    for strength in analysis['strengths']:
                        st.write(f"‚ú® {strength}")
                
                with col4:
                    st.write("**‚ö†Ô∏è Areas for Improvement:**")
                    for weakness in analysis.get('weaknesses', []):
                        st.write(f"üîß {weakness}")

    def _display_film_results(self, results):
        """Display film analysis results"""
        st.success("üéâ Film Analysis Complete!")
        
        # Overall score
        overall_score = results['overall_score']
        st.markdown(f"""
        <div style='text-align: center; padding: 25px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                  border-radius: 15px; margin: 20px 0; border: 3px solid #FFD700;'>
            <h1 style='color: gold; margin: 0; font-size: 48px;'>{overall_score}/5.0</h1>
            <p style='color: white; font-size: 20px; margin: 10px 0;'>üé¨ Overall Magic Score</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Genre insights
        genre_insights = results['genre_insights']
        if genre_insights['detected_genre'] != "Unknown":
            confidence_percent = genre_insights['confidence'] * 100
            st.info(f"üé≠ **Genre Analysis**: Detected **{genre_insights['detected_genre']}** ({confidence_percent:.0f}% confidence)")
        
        # Category scores
        st.subheader("üéØ Category Analysis")
        scores = results['cinematic_scores']
        cols = st.columns(5)
        
        categories = [
            ("üß† Story", scores['story_narrative'], "#FF6B6B"),
            ("üëÅÔ∏è Visual", scores['visual_vision'], "#4ECDC4"),
            ("‚ö° Technical", scores['technical_craft'], "#45B7D1"),
            ("üéµ Sound", scores['sound_design'], "#96CEB4"),
            ("üåü Performance", scores['performance'], "#FFD93D")
        ]
        
        for idx, (name, score, color) in enumerate(categories):
            with cols[idx]:
                st.markdown(f"""
                <div style='text-align: center; padding: 15px; background: {color}; border-radius: 10px; margin: 5px; border: 2px solid white;'>
                    <h4 style='margin: 0; color: white;'>{name}</h4>
                    <h2 style='margin: 8px 0; color: white;'>{score}</h2>
                </div>
                """, unsafe_allow_html=True)
        
        # Summary and insights
        st.subheader("üìñ Analysis Summary")
        st.write(results['smart_summary'])
        
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("‚úÖ Strengths")
            for strength in results['strengths']:
                st.write(f"‚ú® {strength}")
        
        with col2:
            st.subheader("‚ö†Ô∏è Areas for Improvement")
            for weakness in results.get('weaknesses', []):
                st.write(f"üîß {weakness}")
        
        # Recommendations
        st.subheader("üí° Recommendations")
        for recommendation in results['recommendations']:
            st.write(f"üéØ {recommendation}")
        
        # Festival recommendations
        festival_recs = results['festival_recommendations']
        st.subheader("üé™ Festival Recommendations")
        st.write(f"**Level:** {festival_recs['level']}")
        st.write("**Suggested Festivals:**")
        for festival in festival_recs['festivals']:
            st.write(f"‚Ä¢ {festival}")
        
        # Audience analysis
        audience = results['audience_analysis']
        st.subheader("üéØ Target Audience")
        st.write(f"**Primary Audience**: {audience['audience']}")
        st.write(f"**Expected Impact**: {audience['impact']}")

    def _get_video_id(self, url):
        """Extract video ID from YouTube URL"""
        try:
            parsed = urlparse(url)
            if "youtube.com" in parsed.hostname:
                return parse_qs(parsed.query).get("v", [None])[0]
            elif parsed.hostname == "youtu.be":
                return parsed.path[1:]
        except:
            return None

    def _get_video_info(self, video_id):
        """Get video information from YouTube"""
        try:
            response = requests.get(f"https://www.youtube.com/oembed?url=https://www.youtube.com/watch?v={video_id}&format=json", timeout=10)
            if response.status_code == 200:
                data = response.json()
                return {'title': data.get('title', 'Unknown'), 'author': data.get('author_name', 'Unknown'), 'success': True}
        except:
            pass
        return {'success': False}

    def _get_transcript(self, video_id):
        """Get transcript from YouTube video"""
        try:
            transcript_list = YouTubeTranscriptApi.get_transcript(video_id)
            return " ".join([seg["text"] for seg in transcript_list])
        except:
            return "No transcript available. AI will analyze based on film context and metadata."

# --------------------------
# History & Analytics Page
# --------------------------
class HistoryAnalyticsPage:
    def __init__(self, database):
        self.database = database
    
    def show(self):
        st.header("üìà Analysis History & Analytics")
        st.markdown("---")
        
        # Show analysis history
        history = self.database.get_analysis_history()
        
        if not history:
            st.info("üìä No analysis history yet. Start analyzing films to see your history here!")
            return
        
        # Statistics overview
        st.subheader("üìä Analysis Overview")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            total_analyses = len(history)
            st.metric("Total Analyses", total_analyses)
        
        with col2:
            avg_score = np.mean([item['overall_score'] for item in history])
            st.metric("Average Score", f"{avg_score:.1f}/5.0")
        
        with col3:
            genres = [item['detected_genre'] for item in history]
            most_common_genre = max(set(genres), key=genres.count) if genres else "N/A"
            st.metric("Most Common Genre", most_common_genre)
        
        with col4:
            highest_score = max([item['overall_score'] for item in history])
            st.metric("Highest Score", f"{highest_score}/5.0")
        
        # Recent analyses table
        st.subheader("üïí Recent Analyses")
        
        # Convert to DataFrame for better display
        history_df = pd.DataFrame(history)
        history_df = history_df.sort_values('timestamp', ascending=False)
        
        # Display the table
        st.dataframe(
            history_df[['title', 'overall_score', 'detected_genre', 'timestamp']].head(10),
            use_container_width=True
        )
        
        # Genre distribution
        st.subheader("üé≠ Genre Distribution")
        genre_counts = pd.Series(genres).value_counts()
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.bar_chart(genre_counts)
        
        with col2:
            st.write("**Genre Breakdown:**")
            for genre, count in genre_counts.items():
                st.write(f"‚Ä¢ {genre}: {count} films")
        
        # Score distribution over time
        st.subheader("üìà Score Trends")
        
        if len(history) > 1:
            # Create timeline data
            timeline_data = history_df.copy()
            timeline_data['timestamp'] = pd.to_datetime(timeline_data['timestamp'])
            timeline_data = timeline_data.sort_values('timestamp')
            
            st.line_chart(timeline_data.set_index('timestamp')['overall_score'])
        else:
            st.info("Need more analyses to show trends")

# --------------------------
# Main Application
# --------------------------
def main():
    st.sidebar.title("üé¨ FlickFinder AI")
    st.sidebar.markdown("---")
    
    # Initialize components
    analyzer = FilmAnalysisEngine()
    database = FilmDatabase()
    film_interface = FilmAnalysisInterface(analyzer, database)
    ai_tech_page = AITechnologyPage()
    history_page = HistoryAnalyticsPage(database)
    
    # Navigation
    page = st.sidebar.radio("Navigate:", 
        ["üè† Dashboard", "üìà Analytics", "üß† AI Technology", "‚ÑπÔ∏è About"])
    
    if page == "üè† Dashboard":
        film_interface.show_dashboard()
    elif page == "üìà Analytics":
        history_page.show()
    elif page == "üß† AI Technology":
        ai_tech_page.show()
    else:
        st.header("‚ÑπÔ∏è About FlickFinder AI")
        st.write("""
        **FlickFinder AI** is an intelligent film analysis tool that uses AI to evaluate cinematic content.
        
        **Features:**
        - üé¨ Smart genre detection from transcripts and descriptions
        - üìä Multi-category scoring (Story, Visual, Technical, Sound, Performance)
        - üí° AI-powered recommendations for improvement
        - üé™ Festival recommendations based on quality
        - üìÅ Batch CSV processing for multiple films
        - üéØ Target audience analysis
        - üìà Comprehensive analysis history and tracking
        
        **Supported Input Methods:**
        1. **YouTube URLs** - Analyze films directly from YouTube
        2. **Manual Entry** - Enter film details manually
        3. **CSV Upload** - Batch analyze multiple films
        
        **CSV Format:** Your CSV should include columns like:
        - `title`, `director`, `writer`, `genre`, `duration`, `synopsis`
        """)

if __name__ == "__main__":
    main()
